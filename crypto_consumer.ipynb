{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2215a",
   "metadata": {
    "id": "acb2215a"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from confluent_kafka import Consumer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, LSTM, BatchNormalization\n",
    "import pandas as pd\n",
    "from keras import regularizers\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d386d78c",
   "metadata": {
    "id": "d386d78c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/31 19:51:29 WARN Utils: Your hostname, Ubuntu-GPU-84 resolves to a loopback address: 127.0.1.1; using 192.168.90.60 instead (on interface ens160)\n",
      "25/03/31 19:51:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/31 19:51:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# creating the SparkContext\n",
    "sc = SparkContext(master=\"local[4]\")\n",
    "# configing Kafka Consumer\n",
    "conf = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'simple-sentiment-group',\n",
    "    'auto.offset.reset': 'earliest',\n",
    "    'max.poll.interval.ms': '600000'\n",
    "}\n",
    "consumer = Consumer(conf)\n",
    "\n",
    "consumer.subscribe(['crypto_topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rXMmYyxb_8lm",
   "metadata": {
    "id": "rXMmYyxb_8lm"
   },
   "outputs": [],
   "source": [
    "#builds the LSTM model we will use\n",
    "def build_lstm_model(input_data, output_size, neurons=32, activ_func='linear',\n",
    "                     dropout=0.4, loss='mse', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, input_shape=(input_data.shape[1], input_data.shape[2]), kernel_regularizer=regularizers.l2(l2_lambda)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=output_size))\n",
    "    model.add(Activation(activ_func))\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKxqGQevDPhX",
   "metadata": {
    "id": "PKxqGQevDPhX"
   },
   "outputs": [],
   "source": [
    "#normalizing the DataFrame\n",
    "def normalize_zero_base(df):\n",
    "    return df / df.iloc[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_izyo2ORDPac",
   "metadata": {
    "id": "_izyo2ORDPac"
   },
   "outputs": [],
   "source": [
    "#create window data\n",
    "def extract_window_data(df, window_len=5, zero_base=True):\n",
    "    window_data = []\n",
    "    for idx in range(len(df) - window_len):\n",
    "        tmp = df[idx: (idx + window_len)].copy()\n",
    "        if zero_base:\n",
    "            tmp = normalize_zero_base(tmp)\n",
    "        window_data.append(tmp.values)\n",
    "    return np.array(window_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61s6ybinDPSV",
   "metadata": {
    "id": "61s6ybinDPSV"
   },
   "outputs": [],
   "source": [
    "#splits the data 80% training and 20% for testing\n",
    "def train_test_split(df, test_size=0.2):\n",
    "    split_row = len(df) - int(test_size * len(df))\n",
    "    train_data = df.iloc[:split_row]\n",
    "    test_data = df.iloc[split_row:]\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afzClrBSDVQm",
   "metadata": {
    "id": "afzClrBSDVQm"
   },
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "def prepare_data(df, target_col, window_len=10, zero_base=True, test_size=0.2):\n",
    "    train_data, test_data = train_test_split(df, test_size=test_size)\n",
    "    X_train = extract_window_data(train_data, window_len, zero_base)\n",
    "    X_test = extract_window_data(test_data, window_len, zero_base)\n",
    "    y_train = train_data[target_col][window_len:].values\n",
    "    y_test = test_data[target_col][window_len:].values\n",
    "    if zero_base:\n",
    "        y_train = y_train / train_data[target_col][:-window_len].values - 1\n",
    "        y_test = y_test / test_data[target_col][:-window_len].values - 1\n",
    "\n",
    "    return train_data, test_data, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4kz36l08BW0Z",
   "metadata": {
    "id": "4kz36l08BW0Z"
   },
   "outputs": [],
   "source": [
    "#variables to use\n",
    "np.random.seed(42)\n",
    "window_len = 36\n",
    "test_size = 0.2\n",
    "zero_base = True\n",
    "lstm_neurons = 128\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "loss = 'mse'\n",
    "dropout = 0.2\n",
    "optimizer = 'adam'\n",
    "l2_lambda = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e8a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model and saving it for future use\n",
    "def train_model(df,coin_name,target_col = 'close'):\n",
    "    train, test, X_train, X_test, y_train, y_test = prepare_data(\n",
    "    df, target_col, window_len=window_len, zero_base=zero_base, test_size=test_size)\n",
    "    model = build_lstm_model(\n",
    "    X_train, output_size=1, neurons=lstm_neurons, dropout=dropout, loss=loss,\n",
    "    optimizer=optimizer)\n",
    "    history = model.fit(\n",
    "    X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
    "    model.save(f\"{coin_name}_model.keras\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XSINfNl5ciOH",
   "metadata": {
    "id": "XSINfNl5ciOH"
   },
   "outputs": [],
   "source": [
    "# checking if a model does not exist already or the model is old\n",
    "def check_model_status(model_name):\n",
    "    if not os.path.exists(model_name):\n",
    "        return True  # no model exists\n",
    "\n",
    "    last_modified = datetime.datetime.fromtimestamp(os.path.getmtime(model_name))\n",
    "    if (datetime.datetime.now() - last_modified).days > 90:\n",
    "        return True  # a model exist however its more then 3 month old\n",
    "\n",
    "    return False  # a model exist and its updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t4jdEUDocxtC",
   "metadata": {
    "id": "t4jdEUDocxtC"
   },
   "outputs": [],
   "source": [
    "#loading a model that exists \n",
    "def load_model(model_name):\n",
    "    return tf.keras.models.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b0a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_close(model, recent_data, target_col='close', window_len=24, zero_base=True):\n",
    "    # Check that we have enough data\n",
    "    if len(recent_data) < window_len:\n",
    "        raise ValueError(f\"Need at least {window_len} rows of recent data\")\n",
    "\n",
    "    # Slice the latest window_len rows\n",
    "    window_data = recent_data[-window_len:].copy()\n",
    "\n",
    "    # Normalize if needed\n",
    "    if zero_base:\n",
    "        base_value = window_data[target_col].iloc[0]\n",
    "        window_data = window_data / base_value - 1\n",
    "\n",
    "    # Convert to proper shape (1 sample, window_len steps, num_features)\n",
    "    input_array = np.expand_dims(window_data.values, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    normalized_prediction = model.predict(input_array)[0][0]\n",
    "\n",
    "    # Denormalize prediction if needed\n",
    "    if zero_base:\n",
    "        predicted_close = (normalized_prediction + 1) * base_value\n",
    "    else:\n",
    "        predicted_close = normalized_prediction\n",
    "    last_value_in_column = recent_data[target_col].iloc[-1]\n",
    "    if predicted_close < last_value_in_column:\n",
    "        print(f\"value will drop\\nPredicted close price: {predicted_close}, Last close price: {last_value_in_column}\")\n",
    "    else:\n",
    "        print(f\"value will rise\\nPredicted close price: {predicted_close}, Last close price: {last_value_in_column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1efd22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "db1efd22",
    "outputId": "71e39b53-a757-43c8-eb1c-82d8dfbf9d0d"
   },
   "outputs": [],
   "source": [
    "# kafka DataFrame processing\n",
    "def process_messages():\n",
    "    while True:\n",
    "        msg = consumer.poll(timeout=1.0)\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            print(f\"Consumer error: {msg.error()}\")\n",
    "            continue\n",
    "        if msg.key().decode('utf-8') == \"exit\":\n",
    "            break\n",
    "        received_data = msg.value().decode('utf-8')\n",
    "        coin_name = msg.key().decode('utf-8')\n",
    "        df = pd.read_csv(StringIO(received_data))\n",
    "        print(f\"Recieved data for {coin_name}\")\n",
    "        print(df.head())\n",
    "        #check if model exists in format of \"{coin_name}_model.keras\" \n",
    "        if check_model_status(f\"{coin_name}_model.keras\"):\n",
    "            model = train_model(df, coin_name, target_col='close')\n",
    "        else:\n",
    "            model = load_model(f\"{coin_name}_model.keras\")\n",
    "        #writes the next predicted value to the console\n",
    "        if model is not None:\n",
    "            predict_next_close(model, df, target_col='close', window_len=window_len, zero_base=zero_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5ee8f",
   "metadata": {
    "id": "b3d5ee8f",
    "outputId": "84fe6f3c-7cde-4a17-9334-39c5dd117a61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%6|1743442127.240|FAIL|rdkafka#consumer-1| [thrd:Ubuntu-GPU-84.academic.management.afeka.local:9092/0]: Ubuntu-GPU-84.academic.management.afeka.local:9092/0: Disconnected (after 2172510ms in state UP)\n",
      "%3|1743442127.240|FAIL|rdkafka#consumer-1| [thrd:Ubuntu-GPU-84.academic.management.afeka.local:9092/0]: Ubuntu-GPU-84.academic.management.afeka.local:9092/0: Connect to ipv4#127.0.1.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%6|1743442127.240|FAIL|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Ubuntu-GPU-84.academic.management.afeka.local:9092: Disconnected (after 2235060ms in state UP)\n",
      "%3|1743442127.240|FAIL|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Ubuntu-GPU-84.academic.management.afeka.local:9092: Connect to ipv4#127.0.1.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1743442127.241|FAIL|rdkafka#consumer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1743442127.499|FAIL|rdkafka#consumer-1| [thrd:Ubuntu-GPU-84.academic.management.afeka.local:9092/0]: Ubuntu-GPU-84.academic.management.afeka.local:9092/0: Connect to ipv4#127.0.1.1:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "%3|1743442127.516|FAIL|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Ubuntu-GPU-84.academic.management.afeka.local:9092: Connect to ipv4#127.0.1.1:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "%3|1743442127.516|FAIL|rdkafka#consumer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "%3|1743442157.671|FAIL|rdkafka#consumer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 67 identical error(s) suppressed)\n",
      "%3|1743442159.636|FAIL|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Ubuntu-GPU-84.academic.management.afeka.local:9092: Connect to ipv4#127.0.1.1:9092 failed: Connection refused (after 0ms in state CONNECT, 5 identical error(s) suppressed)\n",
      "%3|1743442160.046|FAIL|rdkafka#consumer-1| [thrd:Ubuntu-GPU-84.academic.management.afeka.local:9092/0]: Ubuntu-GPU-84.academic.management.afeka.local:9092/0: Connect to ipv4#127.0.1.1:9092 failed: Connection refused (after 0ms in state CONNECT, 5 identical error(s) suppressed)\n",
      "%4|1743442171.191|SESSTMOUT|rdkafka#consumer-1| [thrd:main]: Consumer group session timed out (in join-state steady) after 45014 ms without a successful response from the group coordinator (broker 0, last error was Success): revoking assignment and rejoining group\n",
      "%3|1743442188.182|FAIL|rdkafka#consumer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 59 identical error(s) suppressed)\n",
      "%3|1743442191.183|FAIL|rdkafka#consumer-1| [thrd:Ubuntu-GPU-84.academic.management.afeka.local:9092/0]: Ubuntu-GPU-84.academic.management.afeka.local:9092/0: Connect to ipv4#127.0.1.1:9092 failed: Connection refused (after 0ms in state CONNECT, 13 identical error(s) suppressed)\n",
      "%3|1743442197.352|FAIL|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Ubuntu-GPU-84.academic.management.afeka.local:9092: Connect to ipv4#127.0.1.1:9092 failed: Connection refused (after 0ms in state CONNECT, 4 identical error(s) suppressed)\n",
      "%3|1743442218.195|FAIL|rdkafka#consumer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/bootstrap: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 32 identical error(s) suppressed)\n",
      "%3|1743442221.196|FAIL|rdkafka#consumer-1| [thrd:Ubuntu-GPU-84.academic.management.afeka.local:9092/0]: Ubuntu-GPU-84.academic.management.afeka.local:9092/0: Connect to ipv4#127.0.1.1:9092 failed: Connection refused (after 0ms in state CONNECT, 38 identical error(s) suppressed)\n"
     ]
    }
   ],
   "source": [
    "# running the consumer program\n",
    "try:\n",
    "    process_messages()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping Kafka Consumer...\")\n",
    "finally:\n",
    "    consumer.close()\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5558c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
